\documentclass[11pt,a4paper,twoside]{article}

\usepackage[T1]{fontenc} % sonst geht \hyphenation nicht mit Umlauten
\usepackage[latin1]{inputenc} % man kann schreiben äöüß, statt "a"o"u"s
%\usepackage[utf8]{inputenc} % wie oben, aber UTF-8 als Encoding statt ISO-8859-1 (latin1)
\usepackage[ngerman,english]{babel} % deutsche Trennregeln, "Inhaltsverzeichnis" etc.
%\usepackage{ngerman} % Alternative zum Babel-Paket oben
\usepackage{mathptmx} % Times-Roman-Schrift (auch für mathematische Formeln)
\usepackage{framed}
\usepackage{longtable}
\usepackage{tabu}


% Zum Setzen von URLs
\usepackage{color}
\definecolor{darkred}{rgb}{.25,0,0}
\definecolor{darkgreen}{rgb}{0,.2,0}
\definecolor{darkmagenta}{rgb}{.2,0,.2}
\definecolor{darkcyan}{rgb}{0,.15,.15}
\usepackage[plainpages=false,bookmarks=true,bookmarksopen=true,colorlinks=true,
  linkcolor=darkred,citecolor=darkgreen,filecolor=darkmagenta,
  menucolor=darkred,urlcolor=darkcyan]{hyperref}

% pdflatex: Bilder in den Formaten .jpeg, .png und .pdf
% latex: Bilder im .eps-Format
\usepackage{graphicx}

\usepackage{fancyhdr} % Positionierung der Seitenzahlen
\fancyhead[LE,RO,LO,RE]{}
\fancyfoot[CE,CO,RE,LO]{}
\fancyfoot[LE,RO]{\Roman{page}}
\renewcommand{\headrulewidth}{0pt}
\setlength{\headheight}{13.6pt} % behebt headheight Warning

% Korrektes Format für Nummerierung von Abbildungen (figure) und
% Tabellen (table): <Kapitelnummer>.<Abbildungsnummer>
\makeatletter
\@addtoreset{figure}{section}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}
\@addtoreset{table}{section}
\renewcommand{\thetable}{\thesection.\arabic{table}}
\makeatother

\sloppy % Damit LaTeX nicht so viel über "overfull hbox" u.Ä. meckert

% Ränder
\addtolength{\topmargin}{-16mm}
\setlength{\oddsidemargin}{25mm}
\setlength{\evensidemargin}{35mm}
\addtolength{\oddsidemargin}{-1in}
\addtolength{\evensidemargin}{-1in}
\setlength{\textwidth}{15cm}
\addtolength{\textheight}{34mm}
%______________________________________________________________________

\begin{document}

\pagestyle{empty} % Vorerst keine Seitenzahlen
\pagenumbering{alph} % Unsichtbare alphabetische Nummerierung

\begin{center}
\textsc{Ludwig-Maximilians-Universität München}\\
Department ``Institut für Informatik''\\
Lehr- und Forschungseinheit Medieninformatik\\
Prof.\ Dr.\ Heinrich Hußmann

\vspace{5cm}
{\large\textbf{Masterarbeit}}\vspace{.5cm}

{\LARGE Entwicklung eines Systems zur Nutzung von VR-Brillen im Unterricht}\vspace{1cm}

{\large Veronika Fuchsberger}\\\href{mailto:veronika.fuchsberger@campus.lmu.de}{veronika.fuchsberger@campus.lmu.de}

\end{center}
\vfill

\begin{tabular}{ll}
Bearbeitungszeitraum: & 01. 08. 2018 bis 30. 01. 2018\\
Betreuer: & Christoph Krichenbauer\\
Verantw. Hochschullehrer: & Prof. Heinrich Hußmann
\end{tabular}
%______________________________________________________________________

\clearpage
\section*{Zusammenfassung}
In der folgenden Arbeit wurden aktuelle VR-Headsets verglichen und nach Preissegmenten und Anwendungsfunktionen eingeordnet. Zudem wurde bisher existierende Software, die Virtual Reality für den Schulunterricht zugänglich macht diskutiert und bewertet und auf die Challenges eingegangen, die Virtual Reality-Systeme generell und im Bezug auf die Nutzung im Schulunterricht momentan haben.
Weiterhin wurde in der Arbeit auf die verschiedenen Inhalte für VR-Systeme eingegangen, welche Quellen es für diese Inhalte gibt und wie sie bearbeitet und selbst erstellt werden können.

Anschließend wurde basierend auf den zuvor erörterten Anforderungen an eine Software, die Lehrkräfte im Unterricht nutzen können, um 360°-Inhalte zu zeigen, VRClassroom entwickelt. Ein zwei-teiliges System, mit dem der Lehrer in eine App auf seinem Computer Inhalte hineinladen kann, die dann in einer Web-App auf VR-Brillen gezeigt werden. Die Lehrkräfte führen dabei das komplette VR-Erlebnis für die Schüler und können 360°-Fotos und -Videos hineinladen, Markierungen setzen und das Video synchronisiert für alle abspielen und pausieren. Außerdem können auch 3D-Modelle in die App geladen werden, die die Lehrkraft dann je nach Bedarf skalieren und drehen kann und an interessanten Stellen Markierungen setzen kann. Um zu sehen, welche Geräte verbunden sind, wird in der Lehrer-App ein Liste mit allen Geräten mit einem Aktivitätsindikator angezeigt. 

Anschließend wurde eine Online-Befragung mit Lehrkräften durchgeführt, bei der die Teilnehmer ein Video gezeigt wurde, das die Nutzung von VRClassroom erklärt, zu dem sie nachfolgend einige Fragen beantworteten. Die Mehrheit der Teilnehmer war dem System gegenüber sehr aufgeschlossen und konnte sich gut vorstellen VRClassroom zukünftig im Unterricht zu verwenden, um 360°-Inhalte zu zeigen.

Abschließend wurde diskutiert wie Zukunft von Virtual Reality im Schulunterricht aussehen könnte und wie VRClassroom weiterentwickelt werden könnte, um die Bedürfnisse von Lehrkräfte noch besser zu erfüllen beziehungsweise welche weiteren Funktionen das System noch interessanter machen würden.

\selectlanguage{english}
\section*{Abstract}

Short abstract of the work, maximum of 250 words.

\selectlanguage{ngerman}
\clearpage


\vfill % Sorgt dafür, dass das Folgende an das Seitenende rutscht

\noindent Ich erkläre hiermit, dass ich die vorliegende Arbeit
selbstständig angefertigt, alle Zitate als solche kenntlich gemacht
sowie alle benutzten Quellen und Hilfsmittel angegeben habe.

\bigskip\noindent München, \today

\vspace{4ex}\noindent\makebox[7cm]{\dotfill}

%______________________________________________________________________

\cleardoublepage
\pagestyle{fancy}
\pagenumbering{roman} % Römische Seitenzahlen
\setcounter{page}{1}

% Inhaltsverzeichnis erzeugen
\tableofcontents

%Abbildungsverzeichnis erzeugen - normalerweise nicht nötig
%\cleardoublepage
%\listoffigures
%______________________________________________________________________

\cleardoublepage

% Arabische Seitenzahlen
\pagenumbering{arabic}
\setcounter{page}{1}
% Geändertes Format für Seitenränder, arabische Seitenzahlen
\fancyhead[LE,RO]{\rightmark}
\fancyhead[LO,RE]{\leftmark}
\fancyfoot[LE,RO]{\thepage}

\section{Einleitung}


%______________________________________________________________________

% Der Befehl \cleardoublepage erscheint nur vor \section, nicht vor
% den "kleineren" Gliederungsbefehlen wie \subsection!
\cleardoublepage % Neue rechte Seite anfangen
\section{Existierende VR-Hardware-Systeme}
Es gibt inzwischen eine große Zahl verschiedener VR-Hardware-Systeme, die sich in drei Gruppen mit unterschiedlichen Anwendungsszenarien unterteilen: Die Computer-gestützten VR-Systeme, die Stand-alone VR-Systeme und die Smartphone-gestützten VR-Systeme.

\subsection{Merkmale von VR-Systemen}
Um die verschiedenen VR-Hardware-Systeme einordnen zu können, gibt es einige Merkmale, auf die ein Käufer achten sollte. Denn die verschiedenen Headsets sind für unterschiedliche Anwendungsszenarien entwickelt worden, sodass ein potenzieller Käufer zuerst entscheiden sollte wie er das VR-Headset einsetzen möchte.

Diese Merkmale können dazu herangezogen werden: Degrees of Freedom (DoF), die Displaygröße und -auflösung, die Frequenz des Displays, Field of View, Rechenleistung und Gewicht des Headsets, die verwendete Tracking-Methode, die mitgelieferten Controller beziehungsweise mögliche Input-Methoden, das Gewicht des Headsets und der Verkaufspreis.

\subsubsection{Degrees of Freedom}
3DoF/ 6DoF
Was bedeutet DoF?

\subsubsection{Display}
Maße, Auflösung, 2 einzelne/ ein großes
Vielleicht Display und Frequenz zu einem Punkt verbinden?

\subsubsection{Frequenz}

\subsubsection{Field of View}

\subsubsection{Rechenleistung}
Welche Chips: CPU \& GPU ?


\subsubsection{Inputmethoden}
Wie in Kapitel XXX (hier Ref einfügen) beschrieben, gibt es drei grundsätzliche Input-Methoden für VR-Headsets: Input über Controller mit verschiedenen Buttons und einem ``Raycaster'' in der VR-Welt, das Auslösen von Touch-Events auf dem Display des VR-Headsets und Voice-Input. 

Da nur solche Headsets Touch-Events auf dem Display registrieren, die ein Smartphone als Display nutzen, sind es ebenso nur diese, die Input durch Touch-Interaktionen mit dem Display als Input erlauben. Das sind vor Allem Google Cardboards, die eine Art ``Arm'' nutzen um auf das Display zu drücken oder einige Nachbauten des ursprünglichen Google Cardboards, die Magneten verwenden um ein Touch-Event auf dem Display auszulösen.
(Diese Technik noch genauer erläutern?) Bei beiden Möglichkeiten ist es allerdings nur möglich an einer bestimmten Stelle ein Touch-Event auszulösen, sie müssen also in Verbindung mit einem Art Gaze-Punkt verbunden werden, um dem Nutzer sinnvollen Input zu erlauben.

Gaze Input? (-> EyeVR)

Bisher gibt es keine Geräte, die mit Voice-Input kontrolliert werden können. Allerdings wäre das sehr wünschenswert, da damit die Nutzung von VR-Systemen auch für Menschen mit körperlichen Behinderungen möglich wird.

\subsubsection{Tracking}
Trackingmethode: kein tracking/ inside out/ Sensoren im Raum


\subsubsection{Gewicht}

\subsubsection{Preis}
Die Preise sind in Dollar, wie sie auf dem amerikanischen Markt zu kaufen sind. Darin sind keine Umsatzsteuern enthalten.


\subsubsection{Liste Quellen etc}
% HTC Vive: https://www.vive.com/de/product/?gclid=EAIaIQobChMIgvauiYfA3wIVBcYYCh3oUwkIEAAYASAAEgLADfD_BwE#vive-spec
Augenabstand:	Einstellung der Pupillendistanz und des Objektivabstands
Sensoren:	SteamVR Tracking, G-Sensor, Gyroskop, Nähesensor
Controller:	Multifunktions-Trackpad, Greifknöpfe, zweistufiger Abzug, Systemknopf, Menütaste
Outside Tracking, Kamera in Headset
% Preis: https://store.eu.vive.com/store?Action=DisplayPage&Locale=de_DE&SiteID=htcemea&id=ThreePgCheckoutShoppingCartPage

Oculus Rift: https://www.vrbound.com/headsets/oculus/rift
Preis: Oculus.com/rift

Playstation VR: https://www.vrbound.com/headsets/sony/playstation-vr, https://www.playstation.com/de-de/explore/playstation-vr/tech-specs/

HTC Vive Focus: https://www.vive.com/cn/product/vive-focus-en/

Oculus Go: https://www.vrbound.com/headsets/oculus/go
Sensoren: Orientational Tracking
has no IPD adjustment


Oculus Quest: https://uploadvr.com/oculus-quest-specs-price-release-date/
has an IPD adjustment
Oculus says Quest?s weight isn?t locked in just yet, but presently it?s about 100 grams heavier than the Rift, which would put it around 570 grams

Mirage Solo: https://www.lenovo.com/us/en/virtual-reality-and-smart-devices/virtual-and-augmented-reality/lenovo-mirage-solo/Mirage-Solo/p/ZZIRZRHVR01
Preis 400\$
General Usage: 2.5 hours
Dimensions: 204 mm x 269.5 mm x 179.86 mm
Sensoren: P-Sensor, Gyroscope, Accelerometer, Magnetometer
Controller: 3DoF Daydream Motion Controller

% Google Cardboard: https://store.google.com/product/google_cardboard

% Samsung Gear VR: https://www.samsung.com/de/wearables/gear-vr-r324/SM-R324NZAADBT/?cid=de_ppc_google_im-wearables-gearvr-q3restructured_20180720_samsungvr-broad&tmcampid=7&tmad=c&tmplaceref=c_DE_IMECOM_Warm_Brand_GearVR_Broad&tmclickref=b_%2Bsamsung%20%2Bvr&gclid=EAIaIQobChMIpLnFnuvC3wIVCKQYCh0XVweYEAAYASAAEgLilfD_BwE

% Google Daydream View: https://store.google.com/product/google_daydream_view_specs


\begin{table}[]
%\begin{tabular}{l|l|l|l|l|l}
\begin{tabu} to \textwidth {XXXXXX}
\textbf{VR-Headset} & HTC Vive & Oculus Rift & Playstation~VR & HTC Vive \newline Focus & Oculus Go \\
\hline
\textbf{DoF} & 3Dof? & gut &hoch & weit & 3DoF   \\
\textbf{Display} & 1080 x 1200 Pixel pro Auge (2160 x 1200 Pixel zusammen), Dual AMOLED 3,6?? diagonal & 2160x1200, 3.5in, OLED  & 5.7in, OLED, 1920x1080 & weit & 2560x1440  \\
\textbf{Frequenz} & 90 Hz & 90 hz & 120 hz & weit & 60-72Hz   \\
\textbf{Field~of~View} & 110° & 100 ° & 100 ° & weit & 100°  \\
\textbf{Inputmethoden } & 3Dof? & Oculus Touch, Xbox One Controller &hoch & weit & Oculus Go Controller  \\
\textbf{Tracking} & 3Dof? & Accelerometer, Gyroscope, Magnetometer & Accelerometer, Gyroscope & weit & orientational  \\
\textbf{Gewicht} & h & 380-470g & 610g & weit & 468g  \\
\textbf{Preis} & 599 Euro & 449 Euro &hoch & weit & 199 Euro 
\end{tabu}
%\end{tabular}

\bigskip

\begin{tabu} to \textwidth {XXXXXX}
\textbf{VR-Headset} & Oculus Quest & Lenovo \newline Mirage Solo & Google \newline Cardboard & Samsung \newline Gear VR & Google \newline Daydream  \\
\hline
\textbf{DoF} & 6 DoF & 6DoF &hoch & weit & sechs  \\
\textbf{Display} & 1600 x 1440 per eye, OLED  & gut & 4 bis 6 Zoll, hängt von genutztem Smartphone ab & hängt von genutztem Smartphone ab & hängt von genutztem Smartphone ab  \\
\textbf{Frequenz} & 72Hz & gut & hängt von genutztem Smartphone ab & hängt von genutztem Smartphone ab & hängt von genutztem Smartphone ab  \\
\textbf{Field~of~View} & 3Dof? & gut & abhängig von Smartphone & 101° & abhängig von Smartphone \\
\textbf{Inputmethoden } & 3Dof? & gut & Touch-Taste an Cardboard & Gear VR Controller & Daydream Controller \\
\textbf{Tracking} & 3Dof? & gut & abhängig von Smartphone & Beschleunigungssensor, Lagesensor, Annäherungssensor + abhängig von Smartphone & abhängig von Smartphone   \\
\textbf{Gewicht} & 3Dof? & 645g & 96 g & 345g & 261 g  \\
\textbf{Preis} & 399 Dollar& 400 Dollar  & 20 Euro & weit & hoch  

\end{tabu}
  \caption{Übersicht  der Merkmale der verschiedenen VR-Headsets}~\label{tab:tableage}
\end{table}





\subsection{Computer-gestützte VR-Hardware}
Die erste Gruppe sind die Computer-gestützten Hardware-Systeme: Sie sind mit einem Kabel mit dem Rechner verbunden, der die Rechenleistung für die eigentlich Brille übernimmt. Sie eignen sich besonders für extrem rechenaufwändige Anwendungen, aber schränken durch ihre Kabel die Bewegungsfreiheit des Nutzers ein.

\subsubsection{Oculus Rift}
\subsubsection{HTC Vive}
\subsubsection{HTC Vive Pro}
\subsubsection{Playstation VR}


\subsection{Stand-alone VR-Hardware}
Die zweite Gruppe sind die Stand-alone Hardware-Systeme wie etwa die Oculus Go, Oculus Quest oder Google Daydream. Es handelt sich hierbei um vollumfängliche Systeme, die ohne weiteres Equipment auskommen und auch keinen Computer benötigen. Da sie mit einem Akku betrieben werden, ist die Betriebsdauer allerdings eingeschränkt und auch die Rechenleistung ist deutlich geringer als die der Computer-gestützten Systeme.

\subsubsection{Oculus Go}
\subsubsection{Oculus Quest}
\subsubsection{Lenovo Mirage Solo}
\subsubsection{HTC Vive Focus}

\subsection{Smartphone gestützte VR-Hardware}
Die dritte Gruppe bilden die Smartphone-gestützten VR-Systeme. Damit sind alle Systeme gemeint, bei denen das Smartphone integriert wird, um die VR-Inhalte zu zeigen. Diese liegen preislich auf einem sehr niedrigen bis mittlerem Niveau und bilden so eine gute Möglichkeit für alle Leute in die Welt der VR-Systeme einzutauchen, ohne direkt mehrere Hundert Euro ausgeben zu müssen.

\subsubsection{Google Cardboard}
\subsubsection{Samsung Gear VR}
\subsubsection{Google Daydream View}

\cleardoublepage % Neue rechte Seite anfangen

\section{Aktuelle Einsatzgebiete von VR}
medizin
Gaming
Forschung
verschiedene Therapien zB Angsttherapien

\subsection{3D in VR}
WebVR macht das schon.
Dadurch muss die Szene doppelt gerendert werden.
Wie entsteht 3d generell?
Augenabstand
\subsection{Eingabemethoden in VR}
Controller
Voice Control

\subsection{Existierende VR-Systeme im Bildungsbereich}
Google Expeditions

\cleardoublepage % Neue rechte Seite anfangen
\section{Aktuelle Challenges an VR-Systemen}
5 Major Challenges in VR: https://channels.theinnovationenterprise.com/articles/5-major-challenges-of-vr-industry

Hier wird gerade besonders daran geforscht oder das gibt es noch nicht, ist aber sehr gewünscht.
\subsection{Virtual Reality Sickness}
Umfrage auf reddit: https://www.strawpoll.me/12015620/r
Unterschied zu motion sickness
Symptome
Lösungen?

\subsection{Mindestalter zur Nutzung von VR-Systemen}
Fast alle Hersteller geben in ihren Nutzungsbedingungen oder Sicherheitsanweisungen ein Mindestalter für die Benutzung ihrer VR-Systeme an. Wie in ~\ref{tab:table1} zu sehen, sind sich die Hersteller sehr einig, dass VR-Headsets nicht für kleine Kinder geeignet sind und frühestens für Jugendliche in Frage kommen.
\bigskip

Oculus weist konkret darauf hin, dass eine Nutzung ihrer Geräte unter 13 Jahren ihren Nutzungsbedingungen widerspricht und diese erst für diese Altergruppe entwickelt sind.  ``The Services are intended solely for users who are aged 13 or older. Any registration for, or use of, the Services by anyone under the age of 13 is unauthorised, unlicensed and in breach of these Terms.'' Es werden allerdings keine genauen Gründe für diese Altersrestriktion angegeben.
  ~\cite{FacebookTechnologiesLLC2018}

Samsung geht dabei noch einen Schritt weiter und warnt vor einer Nutzung unter 13 Jahren, da sich jüngere Kinder in einer ``critical period in visual development''  ~\cite{SAMSUNG} befinden. Zudem sollen auch Kinder über 13 Jahren nur unter Aufsicht einer erwachsenen Person die Gear VR benutzen und dabei darauf achten regelmäßig Pausen zu machen. Eine lange Nutzung soll generell vermieden werden und die Kinder sollen während und nach der Nutzung beobachtet werden, ob sich ihre Fähigkeiten in der Hand-Augen-Koordination, Balance oder Multi-Tasking verschlechtern.

Außerdem wird eine Liste an Symptomen aufgeführt bei deren Anzeichen eine Nutzung sofort unterbrochen werden soll. Das sind: ``seizures, loss of awareness, eye strain, eye or muscle twitching, involuntary movements, altered, blurred, or double vision or other visual abnormalities, dizziness, disorientation, impaired balance, impaired hand-eye coordination, excessive sweating, increased salivation, nausea, lightheadedness, discomfort or pain in the head or eyes, drowsiness, fatigue, or any symptoms similar to motion sickness'', also verschiedenste Probleme beim Sehen und an den Augen sowie Probleme der Konzentration, Koordination und Balance.   ~\cite{SAMSUNG}

HTC dagegen gibt für die Nutzung der HTC Vive beziehungsweise Vive Solo kein genaues Mindestalter an. Sie geben allerdings an, dass das Gerät nicht dafür ausgelegt ist von kleinen Kindern genutzt zu werden. Sie warnen davor, dass Kinder Kleinteile verschlucken könnten oder sich und Andere auf anderem Wege damit verletzen können. Für ältere Kinder empfehlen sie die Aufsicht einer erwachsenen Person und dass die Nutzungszeit nicht zu lang ist. \cite{HTC2016}

Zudem wird für die Nutzung der HTC Vive ein HTC Account benötigt, der laut HTC erst ab 14 Jahren erlaubt ist. \cite{HTCCorporation}


In ihren FAQs gibt Sony an, dass man zur Nutzung ihrer Playstation VR Konsole mindestens zwölf Jahre oder älter sein sollte. Weitere Angaben oder Gründe dieses Mindestalter sind auch hier nicht zu finden. \cite{SonyEntertainmentLLC2017}
\bigskip

Gegenüber all der Warnungen der Geräte-Hersteller gibt Martin Banks, Professor of Optometry, Vision Science, Psychologie, and Neuroscience an der University of California in Berkeley in einem Interview im Frühling 2016 an, dass er ``no concrete evidence that a child of a certain age was somehow adversely affected by wearing a VR headset,'' [keine konkreten Beweise, dass ein Kind in einem gewissen Alter durch das Tragen von VR-Brillen negativ beeinflusst wurde] gefunden hat. Er ist überzeugt, dass die Hersteller der VR-Headsets die Nutzung durch Kinder ausschließen, um sicher sein zu können, dass nicht später bekannt werdende Probleme bei Kindern, die VR-Headsets nutzen, ihnen angelastet werden können. 

Weiter gibt er an, dass die Angst, dass die Entwicklung des Auges negativ beeinflusst wird im Gegensatz zur Nutzung von Büchern oder Smartphones viel unproblematischer ist, das durch die in die VR-Brillen eingebauten Optiken das Auge gar nicht auf eine so nahe Sache fokussiert, sondern auf weiter entfernte und somit keine Schäden der Augen nach sich zieht. 

Banks sieht als Gefahren lediglich die gleichen, die auch für Erwachsene bestehen: Das sind hauptsächlich Virtual Reality Sickness, auch bekannt als Cybersickness, und die Gefahr mit Personen oder Gegenständen im Raum zu kollidieren, während das VR-Headset getragen wird.  Ansonsten bewertet er die Nutzung der VR-Brillen von Kindern unproblematisch. \cite{Hill2016}

\bigskip

Momentan gibt es keine veröffentlichten Forschungsarbeiten zu den Gefahren für Kinder bei der Nutzung von VR-Brillen, dagegen sind viele Arbeiten zu finden, die VR-Systeme in der Therapie von verhaltensauffälligen, lernverzögerten oder behinderten Kindern erfolgreich einsetzen. Es gibt beispielsweise Arbeiten, die .... (HIER NOCH GUTE BEISPIELE RAUSSUCHEN)


\begin{table}[]
\begin{tabular}{p{0.2\linewidth}|p{0.2\linewidth}|p{0.5\linewidth}}
\textbf{VR-Gerät} & \textbf{Mindestalter} & \textbf{Weitere Angaben} \\ \hline
Oculus Rift \newline Oculus Go \newline  Oculus Quest & 13 Jahre & keine  \\
HTC Vive \newline HTC Vive Solo & keine genaue Altersangabe & HTC Account erst ab 14 Jahren  \\
Google Daydream & 13 Jahre & keine  \\
Samsung Gear VR & 13 Jahre & nur unter Aufsicht eines Erwachsenen  \newline regelmäßig Pausen machen \newline Warnung vor einer Vielzahl an Symptomen aus dem Bereich Koordination, Balance und Sehen \\
Playstation VR & 12 Jahre & keine  \\
Google Cardboard & keine Angabe & nur unter Aufsicht eines Erwachsenen
\end{tabular}
  \caption{Übersicht der verschiedenen VR-Headsets mit ihren jeweiligen Nutzungsmindestaltern}~\label{tab:tableage}
\end{table}



\cleardoublepage % Neue rechte Seite anfangen
\section{360°-Inhalte}
Neben der verwendeten Hardware spielen die verfügbaren Inhalte für das Virtual Reality Erlebnis eine erhebliche Rolle. Nur wenn die gezeigten Inhalte richtig in der 360°-Umgebung dargestellt werden bringt die Darstellung Nutzung von VR-Headsets die gewünschte Immersion.

Für 360°-Inhalte gibt es keine speziellen Dateiformate, die Inhalte werden in den gewohnten Formaten gespeichert. Das Panorama wird dazu auf ein zwei-dimensionales Bild gemappt, um problemlos in den bekannten Formaten speicherbar zu sein. Die Information, wie das Panorama gemappt wurde, wird dann in den Metadaten der Datei gespeichert und 360°-fähige Software kann mit diesen Informationen die Panoramas dann wiederum richtig darstellen.

\subsection{360°-Fotos}
\subsubsection{Quellen für 360°-Fotos}
Flickr-Group: https://www.flickr.com/groups/360images4schools/
Flickr Search equirectangluar + Creative Commons: % https://www.flickr.com/search/?text=equirectangular&license=2%2C3%2C4%2C5%2C6%2C9

Google Photo Sphere Community: https://plus.google.com/communities/115970110085205516914/stream/abbc1e71-8239-4ab0-9de3-3f6429e7681f
Download nicht immer möglich

www.360cities.net
Realtiv teuer, dafür tolle Fotos


https://www.airpano.com
Teuer, hat auch Videos

\subsubsection{Erstellung und Bearbeitung von 360°-Fotos}
\subsection{360°-Videos}
\subsubsection{Quellen für 360°-Videos}
\subsubsection{Erstellung und Bearbeitung von 360°-Videos}
\subsection{3D-Modelle}
\subsubsection{Quellen für 3D-Modellen}
\subsubsection{Erstellung und Bearbeitung von 3D-Modellen}
\subsection{360° Sound}
\subsubsection{Quellen für 360°-Sounds}
\subsubsection{Erstellung und Bearbeitung von 360°-Sounds}
\subsection{Virtual Reality Spiele und Anwendungen}
\subsection{360°-Inhalte in 3D}
\subsection{360°-Inhalte in React360}



%\_____________________________________________________________________

\cleardoublepage
\section{Software Entwicklung von VR-Systemen}
\subsection{Native VR-Applikationen}
C++
\subsection{VR im Browser}
\subsubsection{A-Frame}
\subsubsection{React360}
\subsubsection{Three.js}

%\_____________________________________________________________________



\cleardoublepage
\section{Software Projekt: VRClassroom}
\subsection{Nutzungsszenario und Anwendungsfokus}
VRClassroom wurde speziell für die Nutzung in der Schule entwickelt.
Dabei kann die Lehrkraft das VR-Erlebnis für die SchülerInnen führen und ihnen so komplexe 3-dimensionale Inhalte besser vermitteln und eine spannende neue Art des Lernens zu erleben. 
Außerdem wurde Funktionen wie etwa die Seitenleiste mit den verbundenen Geräten entwickelt, die es der Lehrkraft erleichtern sollen VRClassroom in einer Schulklasse einzusetzen und sicher zu stellen, dass alle Geräte verbunden sind und die Inhalte angezeigt werden.

Da viele Schulen noch überhaupt keine Ausrüstung an VR-Headsets haben, lag der Fokus besonders auf der Nutzung des VRClassroom Systems mit einem Smartphone in einem Google Cardboard. Allerdings wurde es bewusst so entwickelt, dass auch mit ``echten'' VR-Headsets das System problemlos weiter genutzt werden kann. So wird den Schulen ermöglicht mit einer sehr geringen Investition zu testen, ob es für sie in Frage kommt und können zu einem späteren Zeitpunkt zu einem elaborierteren Hardware-System wechseln ohne auf neue Software umsteigen zu müssen.

Weitere Einsatzszenarien für VRClassroom könnten Besprechungen im Arbeitsumfeld gehen, bei denen es sich um plastische Inhalte handelt wie zum Beispiel Architekturbüros, Designagenturen oder Landschaftsgärtner handelt. Mit einem 360°-Foto oder -Video könnte der Ist-Zustand besprochen werden und anschließend die Entwürfe in 3D-Modellen vorgeführt werden. Dadurch könnten Kunden sich besser in die Entwürfe hineinversetzen und bewusster entscheiden, was sie haben möchten.

\subsection{Anwender}
Da an Schulen Lehrkräfte und Schülerinnen und Schüler verschiedenster Altersstufen und Leveln an Technikaffinität zu finden sind sollte die Software

\begin{itemize}
  \item Hauptszenario: Lehrer und Schüler im Klassenzimmer
  \item mögliche andere Szenarien: Lerngruppen, Workmeetings
  \item Anwender: Lehrer und Schüler aller Fachrichtungen und mit unterschiedlichsten Skillleveln
  \item deshalb muss es sowohl für Lehrer als auch für Schüler möglichst intuitiv und einfach zu bedienen sein!
  \item Augenmerk bei der Entwicklung lag besonders darauf
\end{itemize}

\subsection{Grundstruktur}
Das VRClassroom System besteht aus zwei verschiedenen Applikationen: Zum einem der Schüler-App, die auf den VR-Systemen läuft mit denen die Schüler sehen können, was der Lehrer ihnen präsentiert, und die Lehrer-App, in der die Lehrkraft die verschiedenen Inhalte hineinladen, Markierungen auf die Inhalte setzen kann und und sehen kann, welche Schüler-Geräte aktuell verbunden sind.

Da viele Lehrer in ihrer Ausbildung oft nicht mit vielen neuen Technologien in Berührung gekommen sind, sondern es gewohnt sind mit den ``klassichen'' Medien zu arbeiten, lag der Augenmerk bei der Entwicklung darauf, dass das benötigte technische Verständnis möglichst niedrig ist und auch Personen, die sich selbst als nicht technikaffin bezeichnen würden, keinerlei Probleme bei der Nutzung haben. Gleiches gilt selbstverständlich auch auf der Seite der Schüler. Da diese aber hauptsächlich passiv agieren, standen hier die Lehrkräfte im Mittelpunkt der Aufmerksamkeit.


\subsection{Lehrer-Applikation}
Die Lehrer-Applikation besteht aus einer Electron-App, die in zwei logische Teile zerlegt ist. Das ist zum einen der main-Prozess, der es erlaubt Zugriffe auf das File-System des Rechners zu machen und für rechenaufwändige Hintergrundprozesse genutzt wird, und zum Anderen der render-Prozess. Der render-Prozess ist der Teil des Programms, das die Lehrkraft letztendlich auf ihrem Bildschirm sieht.

Die Lehrer-App enthält genau genommen zwei render-Prozesse: Die teacher-App, in der die Lehrkraft alle verbundenen Geräte sehen kann und verschiedene Inhalte hineinladen kann, und die student-App, die als iFrame in die teacher-App eingebunden ist und auf den Geräten der Schülern läuft.

Die teacher-App enthält außerdem noch den QR-Code Generator, der in einem zweiten Fenster geladen wird.

Um eine Liste der verbundenen Geräte zu halten und Veränderungen der Inhalte auf die Schüler-Geräte zu synchronisieren, startet die teacher-App einen Websocket-Server, mit dem sich alle Schüler-Geräte verbinden. 

\subsubsection{Verbundene Geräte}
Wie in der Grafik zu sehen hält die teacher-App eine Liste mit allen verbundenen Geräte dieser Session. Sind die Geräte gerade aktiv, werden sie mit einem grünen Icon dargestellt, sind sie inaktiv, mit einem Roten.

Das soll der Lehrkraft erleichtern zu überprüfen, ob die Schüler den gezeigten Stoff verfolgen oder sich anderweitig beschäftigen.

Haben die Schüler bereits einen Namen eingegeben, wird dieser in der Liste angezeigt. Ist dies nicht der Fall wird aus dem user-agent versucht möglichst genau zu schließen, um welches Gerät es sich handelt, sodass der Lehrer zumindest einschränken kann, um welchen Schüler bzw welche Schülerin es sich handeln könnte. 

NEU: Bei Modellen und Videos der loading-Status der einzelnen Geräte

\bigskip

Ein User-Agent kann zum Beispiel wie folgt aussehen: 
\begin{framed}
Mozilla/5.0 (iPhone; CPU iPhone OS 5\_0 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Version/5.1 Mobile/9A334 Safari/7534.48.3
\end{framed}

Daraus lässt sich schließen, dass es sich um eine iPhone handelt, welches Safari benutzt, um die Schüler-App zu laden. Die Oculus Geräte hingegen geben in ihrem User-Agent an, den Oculus Browser zu verwenden und sind so auch gut von den anderen verbundenen Geräten zu unterscheiden. Da aber hier nicht ersichtlich wird welches Oculus-Gerät es genau ist wird nur ``Oculus device'' angegeben und nicht genauer spezifiziert, ob es sich dabei um eine Go, Quest oder Rift handelt.
 %hier Grafik connected clients einfügen% 

\begin{itemize}
  \item startet Websocket Server
  \item generiert QR-Code
  \item Lehrer kann verschiedene Apps starten: 
  \begin{itemize}
  	\item 360° Photos und 3D-Modelle anzeigen und Markierungen einfügen
	\item 360° Videos synchronisiert auf allen Geräten zeigen und play/pause aus Lehrer-App steuern
	\item Streetview photos von locations laden und anzeigen (?)
  \end{itemize}
  \item hält history der zuvor gezeigten Inhalte, um sie vereinfacht wiederanzuzeigen 
 \end{itemize}

\subsubsection{Hineinladen von Inhalten}

 
\subsubsection{Controls}
Overlay über iFrame mit Controls, die sich je nach gezeigtem Inhalt unterscheiden:

\paragraph{Marker}
3D-Modell erstellt.
Leuchtende Farbe -> gut zu finden
Rotation -> erweckt aufmerksamkeit
Marker in Fotos/ Videos und auf Modellen
Skalierung von Markern auf 3D-Modellen zu Entfernung von Kamera
Berechnung der Markerposition im Zylinder und auf 3D Modellen: Aus Mausposition und Fenstergröße wird Strahl berechnet. 
Bei Zylinder wird z auf festen Wert gesetzt, bei 3D Modellen Schnittpunkt mit Modell berechnet.

\paragraph{Video Controls}
Länge des Videos, PLay/ Pause, Timeslider, aktuelle Zeit, Mute/Sound, Marker (nur im pausierten Zustand nutzbar)
\paragraph{Photo Controls}
Name des Fotos, Marker
\paragraph{Model Controls}
Switch: Skalieren/ Drehen, Slider zum Drehen/ Skalieren, Marker

 
\subsection{Kommunikation zwischen Lehrer-App und Schüler-App}
WebSocket Server from Teacher App -> Schüler Gerät meldet sich bei Laden der URL an
Teacher App antwortet mit aktuellem Content
Teacher App schickt bei jeder Änderung ein komplettes Content-Objekt (einige Einträge ggf. leer)
Nachrichten von Schüler Geräten: visibilitychange, loading, Name
Nachrichten von Teacher-App: Jede Veränderung des Inhalts, URL zu Inhalt

\subsection{QR-Code Fenster}
Das QR-Code Fenster ist ein zweites Browserfenster, das aus dem main-Prozess der Electron App auf dem Lehrer-Computer gestartet wird. Es zeigt einen QR-Code, den die SchülerInnen mit ihren Smartphones scannen können, um bequem die URL zu laden, auf der sie die Schüler-Applikation erreichen können. Der QR-Code wird dynamisch beim Öffnen der App generiert.

Für Geräte, die keine Kamera haben oder wenn das Scannen des QR-Codes fehlschlägt, wird zudem unterhalb des QR-Codes die URL angezeigt, unter der die Schüler-Applikation zu erreichen ist. 

Der QR-Code wird in diesem extra Fenster generiert und angezeigt, damit die Lehrkraft dieses Fenster auf einem Beamer anzeigen kann, um den SchülerInnen den Zugang zur Schüler-App ohne umständliches URL-Abtippen zu ermöglichen.

%% HIER SCREENSHOT QR-Code Fenster einfügen

\subsection{Schüler-App}
Um die 

\begin{itemize}
  \item Schüler können Namen angeben, der in Lehrer-App angezeigt wird
  \item läd die von Lehrer-App geschickten Inhalte und zeigt sie synchronisiert an
  \item Schüler können sich in Szene umschauen und Inhalte besser erfahren
\end{itemize}

\subsubsection{Eingabe des Namens}
\subsubsection{Anzeigen von 360°-Fotos}
\subsubsection{Abspielen von 360°-Videos}
\subsubsection{Anzeigen von 3D-Modellen}




\subsubsection{Abspielen von Videos mit Ton}
Da die meisten Browser das automatische Abspielen von Videos mit Ton verbieten, werden 360°-Videos von React360 standardmäßig beim erstellen des Videoplayer-Komponenten ``muted'' auf ``true'' gesetzt. Die Hersteller wollen dadurch die Ablenkungen, die beim surfen auf den Nutzer zukommen, abmildern. Erst wenn der Nutzer ein ``user gesture click'' also einen Klick auf der Website gemacht hat, darf die Tonspur automatisiert abgespielt werden. Wird versucht ein Video mit Ton abzuspielen, ohne das ein Klick gemacht wurden, wird der Videoplayer blockiert und kann gar nicht mehr abspielen. \cite{Decker2017}

Damit React360 in einer single-threaded Umgebung wie einem Webbrowser flüssig ablaufen kann und nicht durch ``blocking behavior'' irgendeiner Art das Rendern unterbrochen wird, ist eine React360-App in zwei Teile aufgeteilt: Die React-Applikation und den Code, der die React Komponenten in 3D Elemente auf dem Bildschirm umwandelt. Die App selbst läuft in einem Webworker, einem anderen Prozess als der des Hauptbrowserfensters. \cite{FacebookInc.2018}

Das führt dazu, das die React360-Elemente nicht als html-Elemente gelten und ein Click-Event auf einem VRButton nicht als Interaktion zählt, um die Erlaubnis zu haben Ton abzuspielen.

Um dieses Hindernis zu umgehen ist nun ein durchsichtiger, Bildschirm-füllender Button über die React360-App gelegt, der bei einem Klick verschwindet, um die Erlaubnis vom Browser zu bekommen Ton abzuspielen. Wurde der Button am Schüler-Gerät geklickt wird ein flag gesetzt, dass die App Ton abspielen darf. Ob dann tatsächlich Ton beim Video abgespielt wird, kann der Lehrer aus der teacher-App einstellen. Auch dort ist das Abspielen von Ton an den Schüler-Geräten standardmäßig erst einmal abgestellt, damit der Lehrer entscheiden kann, ob er nur den Ton aus dem Rechner über Boxen für Alle abspielen möchte oder aus jedem Schüler-Gerät einzeln der Ton kommen soll.

\subsubsection{WebVR Polyfill}
% Let's talk about this!

%______________________________________________________________________
\cleardoublepage

\section{Nutzerstudie und Evaluation}


\subsection{Ursprünglich geplanter Ablauf der Studie}
Da das System speziell für die Nutzung im Schulunterricht entwickelt wurde, wurde auch die Nutzerstudie in diesem Szenario durchgeführt. Dadurch wurde die eigentliche Durchführung der Studie deutlich erschwert, denn viele Lehrer konnten trotz Interesse keine Zeit für die Durchführung der Studie in ihren Unterrichtsstunden freimachen und zudem musste Inhalte gefunden werden, die sich für den Schulunterricht eignen und ein Thema für eine Schulstunde ergeben.

Insgesamt haben sich XXX Lehrkräfte bereit erklärt mit ihrer Klasse das VRClassroom System auszuprobieren und im Anschluss einen Fragebogen auszufüllen. 
Außerdem wurde den SchülerInnen die Möglichkeit gegeben ebenfalls ihre Erfahrungen mit den System in einer kurzen Online-Umfrage zu teilen, was  XXX SchülerInnen aus den ingesamt XXX SchülerInnen, die das System ausprobiert haben, auch gemacht haben.

\bigskip

Für den Test wurde allen SchülerInnen ein Cardboard zur Verfügung gestellt, das die Kinder mir ihrem eigenen Smartphone als VR-Brille genutzt haben. 
Der Rechner, auf dem das Programm installiert war, wurde den Lehrkräften bereitgestellt und den Lehrkräften im Vorfeld eine kurze Einführung in die Software gegeben. 

Da einige Schulen aber teilweise getrennte Netzwerke für Lehrergeräte und Schülergeräte haben oder Websocket-Verbindungen zwischen den Geräten unterdrücken, wurde für die Studie ein extra Netzwerk genutzt, um diese Probleme zu umgehen.
Dafür wurde im Klassenzimmer ein Router aufgestellt, der ein offenes WLAN eröffnete, mit dem sich alle Geräte verbanden. Dieses WLAN war nicht mit dem Internet verbunden und nur für den Zweck des reibungslosen Ablaufs der Studie verwendet. 

\subsubsection{Ablauf der Studie}
Für die Durchführung der Studie war ein Zeitrahmen von 15 bis 20 Minuten veranschlagt. In dieser Zeit sollte die Lehrkraft die App starten, sich alle Schüler-Geräte damit verbinden und die Lehrkraft die eigentlichen Inhalte präsentieren.

Damit alle Studienteilnehmer, Lehrer und Schüler gleichermaßen, die gleichen Erlebnisse haben und sich zu allen Funktionen des Systems eine Meinung bilden können, hatte jede Lehrkraft ein vollständiges Set an Inhalten mit jeweils mindestens einem 360°-Fotos, einem 360°-Video und einem 3D-Modell.
Da die Studie in dem WLAN ohne Internetverbindung durchgeführt wurde konnte die Funktion des Ladens von Google Streetview-Panoramas nicht getestet werden. Dies hätte allerdings nur für die Lehrkraft einen Unterschied bedeutet, da es sich für die Schüler wie jedes andere 360°-Foto verhält.

\subsubsection{Freigabe Kulturministerium}
Da alle Studien, die an Schulen gemacht werden, einer Freigabe des Kultusministeriums bedürfen, wurde im Vorfeld der Studie beim Kultusministerium eine solche Freigabe beantragt. Für den Antrag werden alle Fragebögen und der gesamte Ablauf der Studie an das Kultusministerium zur Prüfung vorgelegt. Das Kultusministerium hat die Durchführung von Studien beschränkt, um den Datenschutz der Schülerinnen und Schüler zu sichern. Da allerdings in der Studie nur die Lehrkräfte befragt werden und die Fragebögen komplett anonym gehalten sind, sind die Daten der Schüler zu keinem Zeitpunkt in Gefahr.

Leider wurde der Antrag nie beantwortet, sodass die gesamte Studie kurzfristig abgesagt werden musste. Es hatten sich bereits 15 Lehrkräfte bereit erklärt mit ihrer Klasse das VRClassroom System auszuprobieren und im Anschluss den Fragebogen zu beantworten, die sehr an dem System interessiert waren. Da das VRClassroom-System speziell für den Einsatz im Unterricht entwickelt wurde, wäre eine Nutzerstudie im Unterricht sehr sinnvoll gewesen, um abschätzen zu können, ob es im aktuellen Zustand einen guten Mehrwert bietet oder noch Anpassungen braucht um gut im Unterrichtsablauf zu funktionieren.

\subsection{Qualitative Nutzerstudie}
\subsubsection{Fragebogen}
\subsubsection{Erkenntnisse}

\subsection{Online-Umfrage}
Um die Meinung möglichst vieler verschiedener Lehrkräfte zum entwickelten VRClassroom System zu erfahren, wurde neben der qualitativen Studie, in der die Studienteilnehmer das System ausprobieren und im Anschluss Feedback geben konnten, noch eine Online-Befragung von Lehrkräften in Bayern durchgeführt. 

Dafür wurde ein Video produziert, welches die Idee und Nutzung von VRClassroom erklärt und die einzelnen Funktionen zeigt, die die App anbietet. Im Anschluss haben die teilnehmenden Lehrkräfte einen kurzen Fragebogen ausgefüllt.

\begin{itemize}
  \item Teilnehmer: Anzahl, geschlechterverteilung, Alter, Schulen
  \item Fragen der Studie
  \item Antworten der Lehrer
  \item Schlüsse daraus
\end{itemize}



%______________________________________________________________________
\cleardoublepage

\section{Ausblick}
\subsection{Weiterentwicklungen an VR-Geräten}
\subsection{Mögliche Weiterentwicklungen an VRClassroom}


\subsubsection{Hosten von VRClassroom Online statt Verbindung mit Lehrer-Rechner}
Vorteile/ Probleme

\subsubsection{Skalierung von 3D-Modellen auf echte Größe}
Um den Schülern zu vermitteln wie groß beziehungsweise klein die Dinge in echt sind, die gerade besprochen werden, könnte eine Funktion in der Lehrer-App eingefügt werden, die die 3D-Modelle auf Originalgröße skaliert. Dazu müsste selbstverständlich alle 3D-Modelle in Originalgröße vorliegen, was nur sehr selten der Fall ist, da diese Funktion für die meisten Verwendungszwecke nicht benötigt wird und daher einfach unbeachtet bleibt.

Um die gezeigten Inhalte gut zu begreifen und auch in der echten Welt einschätzen zu können, würden Schüler allerdings sehr davon profitieren diesen Einblick zu haben. Denn erst wenn man direkt davor steht, kann man begreifen wie groß der Eiffelturm ist oder wie klein eine extrem giftige Spinne wie die schwarze Witwe in Wahrheit ist.

Wie schon erwähnt müssen dazu zum einen die Modelle in der richtigen Größe vorliegen, aber zum anderen müsste auch die VR-Classroom-App angepasst werden, um diese Funktion sinnvoll zu erfüllen. Wird das Modell auf Originalgröße skaliert, die kleiner ist als die Größe, in der man sie genauer betrachten würde ist das kein Problem und könnte direkt erfüllt werden. Problematisch wird die Skalierung wenn sie extrem viel größer wird als das Modell normal angesehen wird, wie zum Beispiel beim Betrachten eines Gebäudes. Wird das Modell in der App extrem groß skaliert, wird es ab einer gewissen Größe nicht mehr vollständig angezeigt und Teile abgeschnitten. Das passiert, da React360 darauf ausgelegt ist, dass die Kamera in einer Art Kugel ist, in der sie sehen kann. Das dient dazu den Rendering-Aufwand nicht zu extrem werden zu lassen. (QUELLE dafür?) Alles was die Kugel durchbricht wird nur bis zum Rand der Kugel gerendert und alles was außerhalb liegt abgeschnitten. 

\subsubsection{Navigation von 3D-Modellen aus Schüler-App}
Momentan können Schüler keinen Einfluss darauf nehmen, welchen Teil eines 3D-Modells sie sehen können und welchen nicht, da nur aus der Teacher-App gesteuert werden kann wie das Modell skaliert und gedreht wird. 
Eine mögliche Erweiterung von VRClassroom könnte sein, dass die Schüler die 3D-Modelle selbstständig drehen und skalieren können beziehungsweise zu anderen Punkten am Modell springen können. 


\subsubsection{Ausfragemodus: Ausgewählter Schüler setzt Markierung}
Eine mögliche Weiterentwicklung von VRClassroom wäre eine Art ``Ausfragemodus'', bei dem die Lehrkraft aus der Liste der verbundenen Geräte eins auswählen kann, das dann eine Markierung setzen kann. Das ausgewählte Gerät hätte dann die Möglichkeit einmalig eine Markierungen zu setzen.

Dafür wäre es notwendig für die Schüler-Geräte eine Möglichkeit zu geben einen Punkt auszuwählen, an dem die Markierung gesetzt werden soll. Bei der aktuellen Implementierung mit einem Smartphone in einem Google Cardboard ist das noch nicht möglich. Dazu müsste mit dem Touch-Event vom Cardboard an der aktuellen Gaze-Position des Nutzers an dieser Stelle ein Marker gesetzt werden. Mit einem Headset, das bereits einen zugehörigen Controller hat, wäre das einfacher zu lösen, da lediglich die Position des ``Rays'' des Controllers abgefragt werden müsste. 

Da die Markierungen auch in der Teacher App über das iFrame mit der Student-App gesetzt werden ist die Kommunikation der Markerposition an die Teacher-App bereits implementiert und müsste nur leicht abgeändert werden. Möglicherweise wäre es gut die von Schülern gesetzten Marker noch in einer anderen Farbe darzustellen wie die der Lehrkraft, um für andere Schüler leichter erkennbar zu machen, welche Marker von welcher Person kommen. 

Momentan können Schüler nicht beeinflussen wie sie 3D-Modelle sehen, sondern nur den von der Lehrkraft ausgewählten Blickwinkel. Um auch auf 3D-Modellen sinnvoll Markierungen setzen zu können wäre es dann auch sehr sinnvoll den Schülern die Möglichkeit zu geben den Blickwinkel des 3D-Modells zu verändern. 

%______________________________________________________________________

\cleardoublepage
\fancyhead[LE,RO,LO,RE]{} % Keine Kopfzeile mehr oben auf jeder Seite
\section*{Inhalt der beigelegten CD}
%______________________________________________________________________

\cleardoublepage

\bibliographystyle{IEEEtran}
\bibliography{literature}

\end{document}
